<p align="center">
  <b>ğŸŒ Language / Langue:</b><br>
  <a href="/simondeqin/Bio-data-workflow-automation/blob/main/05_README_Francais.md">ğŸ‡«ğŸ‡· FranÃ§ais</a> |
  <a href="/simondeqin/Bio-data-workflow-automation/blob/main/05_README_English.md">ğŸ‡¬ğŸ‡§ English</a>
</p>

---

# ğŸ§© Bio-data-workflow-automation  
_Un pipeline complet et Ã©volutif pour enrichir et classifier automatiquement un catalogue Bio._


# ğŸ§© Bio-data-workflow-automation  
_Un pipeline complet et Ã©volutif pour enrichir et classifier automatiquement un catalogue Bio._

---

## **1. Contexte et rÃ©sultats**

### **1.1 Contexte**
Ce projet a Ã©tÃ© rÃ©alisÃ© lors de mon stage chez **GOOD**, une agence de services numÃ©riques pour les fabricants et distributeurs du secteur **Bio**.  
Je travaillais sur la base **BioAnalytics**, qui centralise les ventes en caisse issues dâ€™un panel de magasins partenaires et sert de support aux analyses de marchÃ© fournies aux clients.

### **1.2 Importance et problÃ¨me**
La base BioAnalytics est un outil essentiel dâ€™**intelligence business**, mais sa qualitÃ© doit Ãªtre continuellement contrÃ´lÃ©e.  
Les principales difficultÃ©s rencontrÃ©es :

- erreurs de **classification** pouvant fausser les rÃ©sultats ;  
- **remplissage manuel** lent et rÃ©pÃ©titif ;  
- nÃ©cessitÃ© dâ€™une **mise Ã  jour frÃ©quente** ;  
- **sources variÃ©es** (magasins, catalogues, sites web) rendant la consolidation complexe.  

ğŸ‘‰ Dâ€™oÃ¹ la crÃ©ation dâ€™un pipeline automatisÃ© pour fiabiliser et accÃ©lÃ©rer ces traitements.

### **1.3 RÃ©sultats et valeurs apportÃ©es**
Le pipeline automatise la **normalisation**, la **complÃ©tion** et la **classification** des produits de la base BioAnalytics, amÃ©liorant nettement la rapiditÃ© et la fiabilitÃ© du traitement.

- **EfficacitÃ© accrue** : le travail dâ€™une journÃ©e est ramenÃ© Ã  **30 minâ€“1 h**, grÃ¢ce Ã  des scripts modulaires facilement rÃ©utilisables.  
- **Moins dâ€™erreurs humaines** : lâ€™algorithme dÃ©tecte les incohÃ©rences des donnÃ©es existantes et permet dâ€™ajuster le ratio entre prÃ©cision et taux de remplissage selon les besoins.  
- **QualitÃ© renforcÃ©e** : formats standardisÃ©s, mises Ã  jour rÃ©guliÃ¨res et **KPI de contrÃ´le** assurent la cohÃ©rence et la fiabilitÃ© de la base.

---

## **2. Structure du projet**
```
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ main.py # Script principal
â”‚ â”œâ”€â”€ ml_qualification.py # ModÃ¨les ML pour classification
â”‚ â”œâ”€â”€ extract_contenu.py # Extraction du contenant
â”‚ â”œâ”€â”€ api_openfoodfacts.py # ComplÃ©tion via API OpenFoodFacts
â”‚ â”œâ”€â”€ google_api_search.py # ComplÃ©tion via API Google
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ Dataset_filtre_pour_entrainement_ML.xlsx # Jeu dâ€™entraÃ®nement
â”‚ â””â”€â”€ Demo_brut_V2.xlsx # Exemple dâ€™entrÃ©e
â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ classification_models.pkl
â”‚ â””â”€â”€ label_encoders.pkl
â”‚
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ Demo_classifiÃ©_final.xlsx
â”‚ â””â”€â”€ Statistiques_Remplissage.xlsx
â”‚
â”œâ”€â”€ README_Francais.md              # Version franÃ§aise du README
â”œâ”€â”€ README_English.md               # Version anglaise du README
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```
---

## **3. Composantes et dÃ©roulement**

Le script **main.py** orchestre toutes les Ã©tapes du pipeline, du nettoyage des donnÃ©es Ã  la gÃ©nÃ©ration du fichier final.

- **Ã‰tape 0 â€“ EntraÃ®nement du modÃ¨le ML (optionnel)**  
  EntraÃ®ne un modÃ¨le de classification sur un jeu de donnÃ©es existant, puis sauvegarde les modÃ¨les (.pkl) pour rÃ©utilisation automatique.

- **Ã‰tape 1 â€“ ComplÃ©tion via OpenFoodFacts**  
  Recherche les produits manquants dans la base publique OpenFoodFacts pour remplir les colonnes *DÃ©signation* et *Marque*.

- **Ã‰tape 2 â€“ Extraction du contenant (Regex)**  
  DÃ©tecte le format du produit (ex. â€œ6x250 gâ€, â€œ500 mlâ€) et calcule une valeur standardisÃ©e pour la colonne *Contenant*.

- **Ã‰tape 3 â€“ Classification automatique (ML)**  
  PrÃ©dit les catÃ©gories (*Famille*, *Sous-famille*, *Segment*) selon la dÃ©signation du produit, en respectant la hiÃ©rarchie entre ces niveaux.

- **Ã‰tape 4 â€“ Recherche via API Google**  
  ComplÃ¨te la *Marque* ou la *DÃ©signation* manquante en analysant les premiÃ¨res pages web trouvÃ©es.

- **Ã‰tape 5 â€“ Export et rapport final**  
  GÃ©nÃ¨re un fichier Excel enrichi et un rapport de taux de remplissage avant/aprÃ¨s traitement.

---

## **4. Input et output**

- **Input** : fichier Excel brut (exemple : `data/Demo_brut_V2.xlsx`)  
- **Output** : fichier Excel enrichi (exemple : `outputs/Demo_classifiÃ©_final.xlsx`)  

### **Exemple dâ€™enrichissement**

#### Avant traitement
| EAN           | DÃ©signation              | Marque   | Famille | Sous-famille | Segment | Contenant |
|---------------|--------------------------|----------|---------|--------------|----------|-----------|
| 8721082004091 | POP CORN CARAMEL BIO 75G | NON CREE | 9999    | (vide)       | (vide)  | (vide)    |

#### AprÃ¨s traitement
| EAN           | DÃ©signation (aprÃ¨s)       | Marque (aprÃ¨s)                             | Famille (prÃ©dit) | Sous-famille (prÃ©dit) | Segment (prÃ©dit) | Contenant (calculÃ©) |
|---------------|---------------------------|--------------------------------------------|------------------|-----------------------|------------------|---------------------|
| 8721082004091 | Pop Corn Caramel Bio 75 g | Rempli automatiquement (API OpenFoodFacts / Google) | Ã‰picerie salÃ©e   | Farines / Aides pÃ¢tisseries | Aide pÃ¢tisserie   | 0,075 kg           |

> **Remarques :**
> - *DÃ©signation* : normalisÃ©e automatiquement.  
> - *Marque* : complÃ©tÃ©e via OpenFoodFacts ou recherche Google.  
> - *Famille / Sous-famille / Segment* : prÃ©dits par le modÃ¨le ML hiÃ©rarchique.  
> - *Contenant* : calculÃ© Ã  partir du format du produit (ex. â€œ75Gâ€).

---

## **5. Limites et amÃ©liorations**

### **Limites actuelles**

Trois principaux points freinent encore la performance du pipeline :

- **DÃ©pendance aux sources externes** : la qualitÃ© et la couverture des bases publiques varient selon les catÃ©gories de produits. Les limitations dâ€™usage des services gratuits (comme Google) ralentissent les traitements Ã  grande Ã©chelle.  
- **QualitÃ© des donnÃ©es dâ€™entraÃ®nement** : les modÃ¨les actuels produisent souvent des rÃ©sultats plus prÃ©cis que la base dâ€™origine, mais leurs performances restent limitÃ©es par la qualitÃ© initiale des donnÃ©es. Tant que les sources contiennent des erreurs ou des informations incomplÃ¨tes, la progression reste plafonnÃ©e.  
- **Usage des modÃ¨les de langage (LLM)** : bien quâ€™ils nâ€™aient pas Ã©tÃ© intÃ©grÃ©s directement au pipeline, des outils comme *ChatGPT* ont jouÃ© un rÃ´le important dans lâ€™analyse, la vÃ©rification et lâ€™automatisation partielle des tÃ¢ches. Leur potentiel reste Ã©levÃ©, mais leur intÃ©gration complÃ¨te est freinÃ©e par les contraintes actuelles du secteur de lâ€™IA â€” coÃ»ts Ã©levÃ©s, forte consommation dâ€™Ã©nergie et infrastructures encore limitÃ©es.

### **Pistes dâ€™amÃ©lioration**

Des progrÃ¨s restent possibles Ã  court terme, avec un budget et des ressources raisonnables :

- **AmÃ©liorer lâ€™accÃ¨s aux donnÃ©es** : utiliser des sources plus fiables ou Ã©tendre les droits dâ€™accÃ¨s Ã  des services payants pour garantir une meilleure couverture et des rÃ©sultats plus rapides.  
- **Renforcer lâ€™apprentissage automatique** : enrichir le jeu de donnÃ©es avec des exemples plus variÃ©s et amÃ©liorer la logique de vÃ©rification automatique pour fiabiliser encore les classifications.  
- **Mieux exploiter les LLMs** : adopter des solutions professionnelles ou des interfaces API plus Ã©conomiques, permettant dâ€™intÃ©grer ces outils de maniÃ¨re plus fluide dans le pipeline et dâ€™accroÃ®tre le niveau dâ€™automatisation.

---

ğŸ“˜ *DerniÃ¨re mise Ã  jour : octobre 2025*  
Auteur : **Yuchen LU**
